@article{MackeviciusBahle2018,
abstract = {The ability to identify interpretable, low-dimensional features that capture the dynamics of large-scale neural recordings is a major challenge in neuroscience. Dynamics that include repeated temporal patterns (which we call sequences), are not succinctly captured by traditional dimensionality reduction techniques such as principal components analysis (PCA) and non-negative matrix factorization (NMF). The presence of neural sequences is commonly demonstrated using visual display of trial-averaged firing rates. However, the field suffers from a lack of task-independent, unsupervised tools for consistently identifying sequences directly from neural data, and cross-validating these sequences on held-out data. We propose a tool that extends a convolutional NMF technique to prevent its common failure modes. Our method, which we call seqNMF, provides a framework for extracting sequences from a dataset, and is easily cross-validated to assess the significance of each extracted factor. We apply seqNMF to recover sequences in both a previously published dataset from rat hippocampus, as well as a new dataset from the songbird pre-motor area, HVC. In the hippocampal data, our algorithm automatically identifies neural sequences that match those calculated manually by reference to behavioral events. The second data set was recorded in birds that never heard a tutor, and therefore sang pathologically variable songs. Despite this variable behavior, seqNMF is able to discover stereotyped neural sequences. These sequences are deployed in an overlapping and disorganized manner, strikingly different from what is seen in tutored birds. Thus, by identifying temporal structure directly from neural data, seqNMF can enable dissection of complex neural circuits with noisy or changing behavioral readouts.},
author = {\textbf{Mackevicius*, EL} and Bahle*, AH and Williams, AH and Gu, S and Denissenko, NI and Goldman, MS and Fee, MS},
doi = {10.1101/273128},
journal = {bioRxiv},
publisher = {Cold Spring Harbor Laboratory},
title = {{Unsupervised discovery of temporal sequences in high-dimensional datasets, with applications to neuroscience}},
url = {https://www.biorxiv.org/content/early/2018/03/02/273128},
year = {2018}
}

@article{Mackevicius2018,
title = "Building a state space for song learning ",
journal = "Current Opinion in Neurobiology ",
volume = "49",
number = "",
pages = "59 - 68",
year = "2018",
issn = "0959-4388",
doi = "https://doi.org/10.1016/j.conb.2017.12.001",
url = "https://www.sciencedirect.com/science/article/pii/S0959438817302349",
author = "\textbf{Mackevicius, EL} and Fee, MS",
abstract = "The songbird system has shed light on how the brain produces precisely timed behavioral sequences, and how the brain implements reinforcement learning (RL). \{RL\} is a powerful strategy for learning what action to produce in each state, but requires a unique representation of the states involved in the task. Songbird \{RL\} circuitry is thought to operate using a representation of each moment within song syllables, consistent with the sparse sequential bursting of neurons in premotor cortical nucleus HVC. However, such sparse sequences are not present in very young birds, which sing highly variable syllables of random lengths. Here, we review and expand upon a model for how the songbird brain could construct latent sequences to support RL, in light of new data elucidating connections between \{HVC\} and auditory cortical areas. We hypothesize that learning occurs via four distinct plasticity processes: 1) formation of ‘tutor memory’ sequences in auditory areas; 2) formation of appropriately-timed latent \{HVC\} sequences, seeded by inputs from auditory areas spontaneously replaying the tutor song; 3) strengthening, during spontaneous replay, of connections from \{HVC\} to auditory neurons of corresponding timing in the ‘tutor memory’ sequence, aligning auditory and motor representations for subsequent song evaluation; and 4) strengthening of connections from premotor neurons to motor output neurons that produce the desired sounds, via well-described song \{RL\} circuitry. "
}



 @incollection{Deny2016,
title = {Learning stable representations in a changing world with on-line tSNE: proof of concept in the songbird},
author = "S {Deny*} and \textbf{EL {Mackevicius*}} and TS {Okubo} and G {Berman} and J {Shaevitz} and MS {Fee}",
booktitle = {International Conference on Learning Representations (ICLR)},
year = {2016},
url = {https://openreview.net/forum?id=oVgo1jRRDsrlgPMRsBzY}
}
@article{Okubo2015,
abstract = {Neural sequences are a fundamental feature of brain dynamics underlying diverse behaviours, but the mechanisms by which they develop during learning remain unknown. Songbirds learn vocalizations composed of syllables; in adult birds, each syllable is produced by a different sequence of action potential bursts in the premotor cortical area HVC. Here we carried out recordings of large populations of HVC neurons in singing juvenile birds throughout learning to examine the emergence of neural sequences. Early in vocal development, HVC neurons begin producing rhythmic bursts, temporally locked to a 'prototype' syllable. Different neurons are active at different latencies relative to syllable onset to form a continuous sequence. Through development, as new syllables emerge from the prototype syllable, initially highly overlapping burst sequences become increasingly distinct. We propose a mechanistic model in which multiple neural sequences can emerge from the growth and splitting of a common precursor sequence.},
author = "TS {Okubo} and \textbf{EL {Mackevicius}}  and HL {Payne} and GF {Lynch} and MS {Fee}",
doi = {10.1038/nature15741},
issn = {0028-0836},
journal = {Nature},
month = {Nov},
number = {7582},
pages = {352--357},
pmid = {26618871},
title = {{Growth and splitting of neural sequences in songbird vocal development}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/26618871 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC4957523 http://www.nature.com/doifinder/10.1038/nature15741},
volume = {528},
year = {2015}
}


@misc{COSYNE2015poster, 
author = "\textbf{EL {Mackevicius}} and TS {Okubo} and MS {Fee}",
title = "Aligning auditory and motor representations of syllable onsets in songbird vocal learning",
howpublished = "COSYNE (Computational and systems neuroscience conference) poster",
year = 2015
}

@misc{SfN2014poster, 
author = "\textbf{EL {Mackevicius}} and MS {Fee}",
title = "Aligning auditory and motor representations of syllable onsets in songbird vocal learning",
howpublished = "SfN (Society for Neuroscience) poster",
year = 2014
}

@misc{SquidVideo, 
author = "\textbf{EL {Mackevicius}}",
title = {Squid skin with a mind of its own}, 
year = 2014, 
howpublished = "MIT+K12 Videos, \url{http://k12videos.mit.edu/squid-skin-with-a-mind-of-its-own/}",
}


@article{Okubo2014,
abstract = {The zebra finch is an important model for investigating the neural mechanisms that underlie vocal production and learning. Previous anatomical and gene expression studies have identified an interconnected set of brain areas in this organism that are important for singing. To advance our understanding of how these various brain areas act together to learn and produce a highly stereotyped song, it is necessary to record the activity of individual neurons during singing. Here, we present a protocol for recording single-unit activity in freely moving zebra finches during singing using a miniature, motorized microdrive. It includes procedures for both the microdrive implant surgery and the electrophysiological recordings. There are several advantages of this technique: (1) high-impedance electrodes can be used in the microdrive to obtain well-isolated single units; (2) a motorized microdrive is used to remotely control the electrode position, allowing neurons to be isolated without handling the bird, and (3) a lateral positioner is used to move electrodes into fresh tissue before each penetration, allowing recordings from well-isolated neurons over the course of several weeks. We also describe the application of the antidromic stimulation and the spike collision test to identify neurons based on the axonal projection patterns.},
author = " TS {Okubo} and \textbf{EL {Mackevicius}} and MS {Fee}",
doi = {10.1101/pdb.prot084624},
issn = {1559-6095},
journal = {Cold Spring Harbor protocols},
month = {Dec},
number = {12},
pages = {1273--83},
pmid = {25342072},
title = {{In vivo recording of single-unit activity during singing in zebra finches.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/25342072},
volume = {2014},
year = {2014}
}

@article {Mackevicius15309,
	author = {\textbf{Mackevicius, Emily L.} and Best, Matthew D. and Saal, Hannes P. and Bensmaia, Sliman J.},
	title = {Millisecond Precision Spike Timing Shapes Tactile Perception},
	volume = {32},
	number = {44},
	pages = {15309--15317},
	year = {2012},
	doi = {10.1523/JNEUROSCI.2161-12.2012},
	publisher = {Society for Neuroscience},
	abstract = {In primates, the sense of touch has traditionally been considered to be a spatial modality, drawing an analogy to the visual system. In this view, stimuli are encoded in spatial patterns of activity over the sheet of receptors embedded in the skin. We propose that the spatial processing mode is complemented by a temporal one. Indeed, the transduction and processing of complex, high-frequency skin vibrations have been shown to play an important role in tactile texture perception, and the frequency composition of vibrations shapes the evoked percept. Mechanoreceptive afferents innervating the glabrous skin exhibit temporal patterning in their responses, but the importance and behavioral relevance of spike timing, particularly for naturalistic stimuli, remains to be elucidated. Based on neurophysiological recordings from Rhesus macaques, we show that spike timing conveys information about the frequency composition of skin vibrations, both for individual afferents and for afferent populations, and that the temporal fidelity varies across afferent class. Furthermore, the perception of skin vibrations, measured in human subjects, is better predicted when spike timing is taken into account, and the resolution that predicts perception best matches the optimal resolution of the respective afferent classes. In light of these results, the peripheral representation of complex skin vibrations draws a powerful analogy with the auditory and vibrissal systems.},
	issn = {0270-6474},
	URL = {http://www.jneurosci.org/content/32/44/15309},
	eprint = {http://www.jneurosci.org/content/32/44/15309.full.pdf},
	journal = {Journal of Neuroscience}
}


@misc{COSYNEposter, 
author = "MD Best and \textbf{EL {Mackevicius}} and MA Harvey and SJ Bensmaia",
title = {The coding efficiency and temporal resolution of somatosensory neurons}, 
howpublished = "COSYNE (Computational and systems neuroscience conference) poster",
year = 2011
}

@misc{K12Video, 
author = "\textbf{EL {Mackevicius}}",
title = {Bread Mold Kills Bacteria: Alexander Fleming Discovers Penicillin}, 
year = 2011, 
howpublished = "\url{MIT TechTV K-12 Video Pilot, collaborating with Khan Academy, http://www.khanacademy.org/science/mit-k12/v/bread-mold-kills-bacteria}",
}

@misc{ConfigSps, 
author = "\textbf{EL {Mackevicius}}", 
title = "Configuration Spaces", 
year = 2009, 
howpublished = "\url{http://www.math.uchicago.edu/~may/VIGRE/VIGREREU2009.html}" 
}